Public Cluster
=============================================
$tenantId=""
$subscriptionId=""
$clusterName="arm-workshop-cluster"
$resourceGroup="arm-workshop-rg"
$lwResourceGroup="arm-workshop-rg"
$logworkspaceName="arm-workshop-lw"
$location="eastus"
$masterResourceGroup="master-workshop-rg"
$acrName="armk8sacr"
$keyVaultName="arm-workshop-kv"
$appgwName="arm-workshop-appgw"
$masterVNetName="master-workshop-vnet"
$aksVNetName="arm-workshop-vnet"
$aksSubnetName="arm-workshop-subnet"
$spDisplayName="http://arm-workshop-cluster-sp"
$aadAdminGroupIDs=@("")
$aadTenantID=""
$objectId=""
$baseFolderPath=""
$ingressHostName=""
$listenerHostName=""
$healthProbeHostName=""
$aksPrivateDNSHostName=""
$networkParametersFileName="network-deploy.parameters"
$pfxCertFileName=""

az login --tenant $tenantId
Connect-AzAccount -TenantId $tenantId

Pre-Config
==========
./preconfig.ps1 `
-resourceGroup $resourceGroup `
-masterResourceGroup $masterResourceGroup `
-location "eastus" `
-clusterName $clusterName `
-acrName $acrName `
-keyVaultName $keyVaultName `
-appgwName $appgwName `
-masterVNetName $masterVNetName `
-aksVNetName $aksVNetName `
-pfxCertFileName $pfxCertFileName `
-spDisplayName $spDisplayName `
-subscriptionId $subscriptionId `
-aadAdminGroupIDs $aadAdminGroupIDs `
-aadTenantID $aadTenantID `
-objectId $objectId `
-baseFolderPath $baseFolderPath

Setup
==========

./setup.ps1 `
-isUdrCluster "false" `
-isPrivateCluster "false" `
-resourceGroup $resourceGroup `
-masterResourceGroup $masterResourceGroup `
-lwResourceGroup $lwResourceGroup `
-location $location `
-clusterName $clusterName `
-acrName $acrName `
-keyVaultName $keyVaultName `
-logworkspaceName $logWorkspaceName `
-aksVNetName $aksVNetName `
-aksSubnetName $aksSubnetName `
-version "1.19.13" -addons "monitoring" `
-nodeCount 2 -maxPods 40 `
-vmSetType "VirtualMachineScaleSets" `
-nodeVMSize "Standard_DS2_v2" `
-aksServicePrefix "25.0.6.0/24" `
-aksDNSServiceIP "25.0.6.10" `
-networkPlugin "azure" `
-networkPolicy "azure" `
-nodePoolName "armsyspool" `
-aadAdminGroupIDs $aadAdminGroupIDs `
-aadTenantID $aadTenantID

Virtual Node
=============
./setup.ps1 `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-keyVaultName "arm-workshop-kv" `
-vrnSubnetName "vrn-workshop-subnet"

Create API Nodepool
===================
./nodepool.ps1 `
-nodePoolName "armapipool" `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-version "1.19.13" `
-nodeCount 2 `
-minNodeCount $nodeCount `
-maxNodeCount 20 `
-maxPods 40 `
-nodePoolVMSize "Standard_DS2_V2" `
-osType "Linux" `
-nodepoolMode "User"

Create Devops Nodepool
=======================
./nodepool.ps1 `
-nodePoolName "armdvopspool" `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-version "1.19.11" `
-nodeCount 3 `
-minNodeCount $nodeCount `
-maxNodeCount 20 `
-maxPods 40 `
-nodePoolVMSize "Standard_DS3_V2" `
-osType "Linux" `
-nodepoolMode "User"

Scale API Nodepool
===================
./nodepool.ps1 `
-nodePoolName "armapipool" `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-minNodeCount 2 `
-maxNodeCount 20

Scale Devops Nodepool
===================
./nodepool.ps1 `
-nodePoolName "armdvopspool" `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-minNodeCount 3 `
-maxNodeCount 20

Scale system Nodepool
===================
./nodepool.ps1 `
-nodePoolName "armsyspool" `
-resourceGroup $resourceGroup `
-clusterName $clusterName `
-minNodeCount 2 `
-maxNodeCount 20

Post-Config
============
./postconfig.ps1 `
-resourceGroup $resourceGroup `
-masterResourceGroup "master-workshop-rg" `
-location "eastus" `
-namespaces @("arm-workshop-dev", "arm-workshop-qa", "smoke") `
-clusterName $clusterName `
-acrName "armwkshpacr" `
-keyVaultName "arm-workshop-kv" `
-masterVNetName "master-workshop-vnet" `
-aksVNetName "arm-workshop-vnet" `
-ingressSubnetName "arm-workshop-ing-subnet" `
-ingressNodePoolName "armsyspool" `
-appgwName "arm-workshop-appgw" `
-appgwSubnetName "arm-workshop-appgw-subnet" `
-appgwTemplateFileName "armauto-appgw-deploy" `
-appgwConfigFileName "armauto-config-appgw" `
-ingressControllerIPAddress "12.0.5.100" `
-subscriptionId $subscriptionId `
-baseFolderPath $baseFolderPath


Remove
==========
./remove.ps1 `
-resourceGroup $resourceGroup `
-lwResourceGroup "monitoring-workshop-rg" `
-masterResourceGroup "master-workshop-rg" `
-clusterName $clusterName `
-acrName "armwkshpacr" `
-keyVaultName "arm-workshop-kv" `
-appGwName "arm-workshop-appgw" `
-logworkspaceName "arm-workshop-lw" `
-masterVNetName "master-workshop-vnet" `
-aksVNetName "arm-workshop-vnet" `
-ingressHostName "internal.wkshpdev.com" `
-subscriptionId "6bdcc705-8db6-4029-953a-e749070e6db6"

Get-AzKeyVault -InRemovedState 
Remove-AzKeyVault -VaultName arm-workshop-kv -InRemovedState -Location eastus -Force

Connect to Public Cluster
===========================
az login --tenant $tenantId
az aks get-credentials -g $resourceGroup -n $clusterName

=================================================================================

kubectl config set-context --current --namespace=aks-workshop-dev
kubectl config set-context --current --namespace=aks-workshop-qa
kubectl config set-context --current --namespace=smoke

Helms
=====
RBAC
=====
helm create rbac-chart

helm install rbac-chart -n aks-workshop-dev ./rbac-chart/ -f ./rbac-chart/values-dev.yaml
helm upgrade rbac-chart -n aks-workshop-dev ./rbac-chart/ -f ./rbac-chart/values-dev.yaml

helm install rbac-chart -n aks-workshop-qa ./rbac-chart/ -f ./rbac-chart/values-qa.yaml
helm upgrade rbac-chart -n aks-workshop-qa ./rbac-chart/ -f ./rbac-chart/values-qa.yaml

helm uninstall rbac-chart

INGRESS
=====

helm create ingress-chart

helm install  ingress-chart -n aks-workshop-dev ./ingress-chart/ -f ./ingress-chart/values-dev.yaml
helm upgrade  ingress-chart -n aks-workshop-dev ./ingress-chart/ -f ./ingress-chart/values-dev.yaml

helm uninstall ingress-chart -n aks-workshop-dev

helm install  ingress-chart -n aks-workshop-qa ./ingress-chart/ -f ./ingress-chart/values-qa.yaml
helm upgrade  ingress-chart -n aks-workshop-qa ./ingress-chart/ -f ./ingress-chart/values-qa.yaml

helm uninstall ingress-chart -n aks-workshop-qa

helm create smoke-ingress-chart

helm install  smoke-ingress-chart -n smoke ./ingress-chart/ -f ./ingress-chart/values-smoke.yaml
helm upgrade  smoke-ingress-chart -n smoke ./ingress-chart/ -f ./ingress-chart/values-smoke.yaml

helm uninstall smoke-ingress-chart -n smoke

TESTS
======
az acr import -n akswkshpacr --source docker.io/library/nginx:alpine -t nginx:alpine (Public)
az acr import -n akswkshpprvacr --source docker.io/library/nginx:alpine -t nginx:alpine (Private)

helm create smoke-tests-chart

helm install smoke-tests-chart -n aks-workshop-dev ./smoke-tests-chart/ -f ./smoke-tests-chart/values-smoke.yaml
helm upgrade smoke-tests-chart -n aks-workshop-dev ./smoke-tests-chart/ -f ./smoke-tests-chart/values-smoke.yaml

helm uninstall smoke-tests-chart

APIs
=====
az acr import -n akswkshpacr --source aksltacr.azurecr.io/ratings-api:v1.0.0 -t ratings-api:v1.0.0 (Public)
az acr import -n akswkshpacr --source aksltacr.azurecr.io/ratings-web:v1.0.0 -t ratings-web:v1.0.0 (Public)

az acr import -n akswkshpacr --source aksltacr.azurecr.io/ratings-api:v1.0.0 -t ratings-api:v1.0.0 (Private)
az acr import -n akswkshpacr --source aksltacr.azurecr.io/ratings-web:v1.0.0 -t ratings-web:v1.0.0 (Private)

APIM gateway
=============

k create secret generic aks-workshop-apim-gateway-token -n aks-workshop-dev --from-literal=value="GatewayKey <gateway-key>"  --type=Opaque
k apply -f aks-workshop-apim-gateway.yaml

k delete secrets/aks-workshop-apim-gateway-token -n aks-workshop-dev
k delete -f aks-workshop-apim-gateway.yaml

OAuth2
=======

https://hybrid-workshop-apim.developer.azure-api.net/signin-oauth/code/callback/aksapioauth2
https://hybrid-workshop-apim.developer.azure-api.net/signin-oauth/implicit/callback

<validate-jwt header-name="Authorization" failed-validation-httpcode="401" failed-validation-error-message="Unauthorized. Access token is missing or invalid.">
    <openid-config url="https://login.microsoftonline.com/<tenant-id>/.well-known/openid-configuration" />
    <required-claims>
        <claim name="aud">
            <value><aud></value>
        </claim>
    </required-claims>
</validate-jwt>

Linkerd
=======

brew install step

step certificate create root.linkerd.cluster.local root.crt root.key \
  --profile root-ca --no-password --insecure

step certificate create identity.linkerd.cluster.local issuer.crt issuer.key \
  --profile intermediate-ca --not-after 8760h --no-password --insecure \
  --ca root.crt --ca-key root.key

curl -sL https://run.linkerd.io/install | sh
linkerd check --pre

linkerd install | kubectl apply -f -
OR
linkerd install \
  --identity-trust-anchors-file root.crt \
  --identity-issuer-certificate-file issuer.crt \
  --identity-issuer-key-file issuer.key \
  | tee \
    >(kubectl --context=aks-workshop-cluster apply -f -)

linkerd check
linkerd version
k get deploy nginx-deploy -n smoke -o yaml | linkerd inject - | k apply -f -
k get deploy nginx-deploy -n smoke -o yaml | linkerd uninject - | k apply -f -


linkerd uninstall | kubectl delete -f -

helm repo add linkerd https://helm.linkerd.io/stable
exp=$(date -v+8760H +"%Y-%m-%dT%H:%M:%SZ")

helm install linkerd2 \
  --set-file identityTrustAnchorsPEM=root.crt \
  --set-file identity.issuer.tls.crtPEM=issuer.crt \
  --set-file identity.issuer.tls.keyPEM=issuer.key \
  --set identity.issuer.crtExpiry=$exp \
  linkerd/linkerd2


================================================================================

